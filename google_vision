#!/usr/bin/python
import base64
import os
import sys
from google.cloud import vision_v1

client = vision_v1.ImageAnnotatorClient()


for filename in os.listdir("/home/lxy/GitHub/EC601-Project1/images/"):
    print (filename)
    name = '/home/lxy/GitHub/EC601-Project1/images/'+filename
    with open(name, 'r') as image:
        image_content = image.read()

        encoded_content = base64.b64encode('image_content')
    print (encoded_content)
     #request =  {'image': {'content': {encoded_content},},}
     #response = client.annotate_image(request)
     #print(response)
        
    #data = {"requests":[{"image":{"content": encoded_content},"features":[{"type":"FACE_DETECTION","maxResults":1}]}]}
    #r = requests.post(url=url,json=data)
    #x = json.loads(r.text)
    #print(x['responses'])



#request = {'image': {'source': {'image_uri': '/home/lxy/GitHub/EC601-Project1/images/0.jpg'},},}
#response = client. batch_annotate_images(requests)


#requests=[]
#response = client.annotate_image(request)
